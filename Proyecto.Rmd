---
title: "Proyecto "
author: "Joshua Cervantes/Moisés Monge"
date: "`r format(Sys.time(), '%d %B %Y')`"
mail: "joshua.cervantes@ucr.ac.cr"
linkedin: ""
twitter: ""
github: "afr063426"

home: ""
# !!! You need to provide a logo image here !!! Or just delete the field for no logo
logo: ""
output:
  prettydoc::html_pretty:
      theme: cayman
      highlight: github
      math: katex
      toc: true
      toc_depth: 2
      code_menu: true

---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, width = 60)
## Packages that are needed
library(devtools)
library(prettydoc)
library(rmarkdown)
library(tidyverse)
library(kableExtra)
library(magrittr)
library(jcolors)
library(xtable)
library(rjags) #Gibbs method
library(ecoforecastR) #This packages is used to forecast
library(ggcorrplot)
options(scipen = 999, digits = 5)
#options(scipen = 999, digits = 5, OutDec = ",")


#We comment beacuse only is needed to create the table
#used with all the stations
#---------------------------------------
# We write all the tables

#list_documents <- unlist(list.files(path="PRSA_Data_20130301-20170228",all.file=TRUE,full.names=TRUE))[-(1:2)]

#We proceed to join all in an unique file
#data <- read.csv(list_documents[1])
#for(i in list_documents[-1]){
#    aux <- read.csv(i)
#    data <- rbind(data,aux)
#}

#We write a document with all the stations
#write.csv(data, "datos.csv")
#-----------------------------------------
#We read the documento
data <- read.csv("datos.csv")
data<-data[-1]
data$station<-as.factor(data$station)
stations <- unique(data$station)
```


```{r Table_Head}
#We create a table in format latex for the work

head_first_5 <- head(data, n=5)

print(xtable(head_first_5, type = "latex", tabular.environment="longtable"),
    include.rownames=FALSE, file = "head_5.tex")

```


```{r Summary_5}
#We create the summary of five numbers for 
#We select only the numeric kind
numeric_cols <- data%>%select_if(is.numeric)

#We select the first numeric that is considered important
n_col_PM2.5 <- which(colnames(numeric_cols)=="PM2.5")

#We select the last numeric that is considered important
n_col_WSPM <- which(colnames(numeric_cols)=="WSPM")


names_cols <- colnames(numeric_cols)

summary_5_number <- data.frame("Variable" = character(),
                "Mínimo"=numeric(), 
                "Q1"=numeric(),
                "Mediana"=numeric(),
                "Q3"=numeric(),
                "Máximo"=numeric()
                )


#Summary 5 numberts taking information of twelve stations
summary_data_frame <- function(dat){
    quantiles <- quantile(dat, na.rm = TRUE)
    quantiles <- data.frame("Mínimo"=quantiles[1], 
                "Q1"=quantiles[2],
                "Mediana"=quantiles[3],
                "Q3"=quantiles[4],
                "Máximo"=quantiles[5])
    return(quantiles)
}




for(i in n_col_PM2.5:n_col_WSPM){
    aux <- cbind("Variable" = names_cols[i], summary_data_frame(numeric_cols[i]))
    summary_5_number <- rbind(summary_5_number, aux)
}
#Data frame to long format


print(xtable(summary_5_number, type = "latex", tabular.environment="longtable"),
    include.rownames=FALSE, file = "summary_5_number.tex")


#We create a summary of five numbers for PM2.5 grouping by station

summary_2.5_station <- data.frame("Estación" = character(),
                "Mínimo"=numeric(), 
                "Q1"=numeric(),
                "Mediana"=numeric(),
                "Q3"=numeric(),
                "Máximo"=numeric()
                )
for(i in stations){
    PM2.5_aux <- data%>%filter(station == i)%>%select(PM2.5)
    aux <- cbind("Estación" = i, summary_data_frame(PM2.5_aux))
    summary_2.5_station <- rbind(summary_2.5_station, aux)
}
print(xtable(summary_2.5_station, type = "latex", tabular.environment="longtable"),
    include.rownames=FALSE, file = "summary_2.5_station.tex")

#Se elimina lo que no se va a volver a usar
rm(aux,head_first_5,numeric_cols,PM2.5_aux,summary_2.5_station,summary_5_number, i,k,n_col_PM2.5,n_col_WSPM,
   names_cols,intervalos,stations)
```




```{r}
#Frecuencia de lluvia
Frecuencia_lluvia<-data%>%select(RAIN,station)

#Se calcula la cantidad de clases que deberían haber
k<-nclass.Sturges(Frecuencia_lluvia$RAIN)

#Se contruyen los intervalos
intervalos<-cut(Frecuencia_lluvia$RAIN,breaks = seq(min(Frecuencia_lluvia$RAIN, na.rm = T),max(Frecuencia_lluvia$RAIN, na.rm = T),(max(Frecuencia_lluvia$RAIN, na.rm = T)-min(Frecuencia_lluvia$RAIN, na.rm = T))/k),right = F, na.rm = T, include.lowest = TRUE)

#Se le adjuntan los intervalos a la tabla que tenemos de anomalia y de region
Frecuencia_lluvia<-Frecuencia_lluvia%>%mutate(IntervaloLluvia=intervalos)

#Se genera la tabla de frecuencias

FA<-table(Frecuencia_lluvia$IntervaloLluvia,Frecuencia_lluvia$station)

#Se coloca la matriz en un Data Frame
FA<-as.data.frame(FA)
FA<-FA%>%spread(Var2,Freq)

FA<-rbind(FA, c("Total",colSums(Filter(is.numeric, FA))))

#Se contruye la tabla que va ser pasada a latex
print(xtable(FA, type = "latex", tabular.environment="longtable"),include.rownames=FALSE, file = "frecuenciaLluvia.tex")

#Se elimina la tabla que tiene las frecuencias segun temperatura y anomalia
rm(FA,Frecuencia_lluvia,intervalos)



```

```{r}
#Frecuencia de PM2
Frecuencia_PM2.5<-data%>%select(PM2.5,station)

#Se calcula la cantidad de clases que deberían haber
k<-nclass.Sturges(Frecuencia_PM2.5$PM2.5)

#Se contruyen los intervalos
intervalos<-cut(Frecuencia_PM2.5$PM2.5,breaks = seq(min(Frecuencia_PM2.5$PM2.5, na.rm = T),max(Frecuencia_PM2.5$PM2.5, na.rm = T),(max(Frecuencia_PM2.5$PM2.5, na.rm = T)-min(Frecuencia_PM2.5$PM2.5, na.rm = T))/k),right = F, na.rm = T, include.lowest = TRUE)

#Se le adjuntan los intervalos a la tabla que tenemos de anomalia y de region
Frecuencia_PM2.5<-Frecuencia_PM2.5%>%mutate(IntervaloPM2=intervalos)

#Se genera la tabla de frecuencias

FA<-table(Frecuencia_PM2.5$IntervaloPM2,Frecuencia_PM2.5$station)
#FA<-prop.table(FA)
#Se coloca la matriz en un Data Frame
FA<-as.data.frame(FA)
FA<-FA%>%spread(Var2,Freq)
FA<-rbind(FA, c("Total",colSums(Filter(is.numeric, FA))))


#Se contruye la tabla que va ser pasada a latex
print(xtable(FA, type = "latex", tabular.environment="longtable"),include.rownames=FALSE, file = "frecuenciasPM2.tex")

#Se elimina la tabla que tiene las frecuencias segun temperatura y anomalia
rm(FA,Frecuencia_PM2.5,intervalos)



```





# Modelling

We are going to mode using Bayesian Analysis of State Space Models.
What we are going to do is the nextone:

1. Select the station.
2. Delete the last 31 observations.
3. We take the mean of each variable.
4. Apply the model, taking in consideration one new variable.
5. Test fit using AIC.
6. Select best model. 
7. Move to step 3 again to select another new variable, until finish with all variables.
8. Forecast the last 31 observations.
```{r}
data%<>%mutate("Date"=as.Date(paste(year,month,day,sep="-"),format="%Y-%m-%d"))
head(data)

data_means <- data%>%group_by(station,Date)%>%summarise("PM2.5"=mean(PM2.5,na.rm=TRUE),
                "SO2"=mean(SO2,na.rm=TRUE),
                "NO2"=mean(NO2,na.rm=TRUE),
                "CO"=mean(CO,na.rm=TRUE),
                "O3"=mean(O3,na.rm=TRUE),
                "TEMP"=mean(TEMP,na.rm=TRUE),
                "PRES"=mean(PRES,na.rm=TRUE),
                "DEWP"=mean(DEWP,na.rm=TRUE),
                "RAIN"=mean(RAIN,na.rm=TRUE),
                "WSPM"=mean(WSPM,na.rm=TRUE))
data_means[is.na(data_means)]<-NA
write.csv(file="data_means.csv",data_means)


ggsave("cor_means.pdf",ggcorrplot(cor(data_means[,-c(1,2)],use = "complete.obs")))
#hist(data_means$PM2.5)
head(data_means)
```


```{r}
#We are going to use the function
#fit_dlm that is part of the package ecoforecast
AIC <- function(y,y_hat,k){
    SSE <- sum((y-y_hat)^2)
    n <- length(y)
    AIC <- log(SSE/n)+(n+2*(k+1))/n
    return(AIC)
}

#Example of structure function
#dlm <- fit_dlm(model=list(obs="PM2.5",fixed="~ 1 + X + Variable"))
#cat(dlm) returns the code created and given to rjags
dlm <- function(data,arg,k){
    fit <- fit_dlm(model = list(obs="PM2.5",fixed = args),data)
    smooth <- as.matrix(fit$predict)
    return(AIC(data$PM2.5,smooth,k))

}

concat <- function(best_model,variable){
    return(paste(best_model,variable, sep = " + "))
}
fit <- function(station,data){
    data_train <- data%>%filter(station==station)
    data_train <- data_train[-(nrow(data)-(0:31)),]
    variables <- colnames(data_train[,-(1:2)])
    best_model <- "~ 1 + X"
    k <- 2
    print("Hola")
    while(length(variables)>=1){
        best_aux <- unlist(lapply(FUN = concat, X=variables,best_model = best_model))
        AIC_aux <- unlist(mapply(FUN = dlm, X=best_aux,data=list(data_train),k=k))
    print(best_aux)
        min <- min(AIC_aux)
        if (AIC<=min){
         break   
        }else{
            variable <- variables(which(AIC_aux==min)[1])
            variables <- variables[-which(AIC_aux==min)[1]]
            best_model <- paste(best_model,variable,sep = " + ")
            k <- k+1
        }
    }
    return(data.frame("Station"=station,"Model" = best_model,"AIC" = AIC))
}
models <- data.frame("Station" = character(),"Model" = character(),"AIC"=numeric())
fit(stations[1],data_means)
prueba <- data_means%>%filter(station==stations[2])

fit_dlm(model = list(obs="PM2.5",fixed = "~1 + X + CO"),prueba)
fit_dlm(model = list(obs="PM2.5",fixed = args),data_means)s

```

