---
title: "Proyecto "
author: "Joshua Cervantes/Moisés Monge"
date: "`r format(Sys.time(), '%d %B %Y')`"
mail: "joshua.cervantes@ucr.ac.cr"
linkedin: ""
twitter: ""
github: "afr063426"

home: ""
# !!! You need to provide a logo image here !!! Or just delete the field for no logo
logo: ""
output:
  prettydoc::html_pretty:
      theme: cayman
      highlight: github
      math: katex
      toc: true
      toc_depth: 2
      code_menu: true

---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, width = 60)
## Packages that are needed
library(devtools)
library(prettydoc)
library(rmarkdown)
library(tidyverse)
library(kableExtra)
library(magrittr)
library(jcolors)
library(xtable)
library(rjags) #Gibbs method
library(ecoforecastR) #This packages is used to forecast
library(ggcorrplot)
library(dlm) #For space-state
options(scipen = 999, digits = 5)
#options(scipen = 999, digits = 5, OutDec = ",")
setwd("C:/Users/saac9/OneDrive - Universidad de Costa Rica/Documents/UCR/2022/Modelos_Lineales/Proyecto_Mod_Lin")

#We comment beacuse only is needed to create the table
#used with all the stations
#---------------------------------------
# We write all the tables

#list_documents <- unlist(list.files(path="PRSA_Data_20130301-20170228",all.file=TRUE,full.names=TRUE))[-(1:2)]

#We proceed to join all in an unique file
#data <- read.csv(list_documents[1])
#for(i in list_documents[-1]){
#    aux <- read.csv(i)
#    data <- rbind(data,aux)
#}

#We write a document with all the stations
#write.csv(data, "datos.csv")
#-----------------------------------------
#We read the documento
data <- read.csv("datos.csv")
data<-data[-1]
data$station<-as.factor(data$station)
stations <- unique(data$station)
data%<>%mutate("Date"=as.Date(paste(year,month,day,sep="-"),format="%Y-%m-%d"))
```


```{r Table_Head}
#We create a table in format latex for the work

head_first_5 <- head(data, n=5)

print(xtable(head_first_5, type = "latex", tabular.environment="longtable"),
    include.rownames=FALSE, file = "head_5.tex")

```


```{r Summary_5}
#We create the summary of five numbers for 
#We select only the numeric kind
numeric_cols <- data%>%select_if(is.numeric)

#We select the first numeric that is considered important
n_col_PM2.5 <- which(colnames(numeric_cols)=="PM2.5")

#We select the last numeric that is considered important
n_col_WSPM <- which(colnames(numeric_cols)=="WSPM")


names_cols <- colnames(numeric_cols)

summary_5_number <- data.frame("Variable" = character(),
                "Mínimo"=numeric(), 
                "Q1"=numeric(),
                "Mediana"=numeric(),
                "Q3"=numeric(),
                "Máximo"=numeric()
                )


#Summary 5 numberts taking information of twelve stations
summary_data_frame <- function(dat){
    quantiles <- quantile(dat, na.rm = TRUE)
    quantiles <- data.frame("Mínimo"=quantiles[1], 
                "Q1"=quantiles[2],
                "Mediana"=quantiles[3],
                "Q3"=quantiles[4],
                "Máximo"=quantiles[5])
    return(quantiles)
}




for(i in n_col_PM2.5:n_col_WSPM){
    aux <- cbind("Variable" = names_cols[i], summary_data_frame(numeric_cols[i]))
    summary_5_number <- rbind(summary_5_number, aux)
}
#Data frame to long format


print(xtable(summary_5_number, type = "latex", tabular.environment="longtable"),
    include.rownames=FALSE, file = "summary_5_number.tex")


#We create a summary of five numbers for PM2.5 grouping by station

summary_2.5_station <- data.frame("Estación" = character(),
                "Mínimo"=numeric(), 
                "Q1"=numeric(),
                "Mediana"=numeric(),
                "Q3"=numeric(),
                "Máximo"=numeric()
                )
for(i in stations){
    PM2.5_aux <- data%>%filter(station == i)%>%select(PM2.5)
    aux <- cbind("Estación" = i, summary_data_frame(PM2.5_aux))
    summary_2.5_station <- rbind(summary_2.5_station, aux)
}
print(xtable(summary_2.5_station, type = "latex", tabular.environment="longtable"),
    include.rownames=FALSE, file = "summary_2.5_station.tex")

#Se elimina lo que no se va a volver a usar
rm(aux,head_first_5,numeric_cols,PM2.5_aux,summary_2.5_station,summary_5_number, i,k,n_col_PM2.5,n_col_WSPM,
   names_cols,intervalos,stations)
```




```{r}
#Frecuencia de lluvia
Frecuencia_lluvia<-data%>%select(RAIN,station)

#Se calcula la cantidad de clases que deberían haber
k<-nclass.Sturges(Frecuencia_lluvia$RAIN)

#Se contruyen los intervalos
intervalos<-cut(Frecuencia_lluvia$RAIN,breaks = seq(min(Frecuencia_lluvia$RAIN, na.rm = T),max(Frecuencia_lluvia$RAIN, na.rm = T),(max(Frecuencia_lluvia$RAIN, na.rm = T)-min(Frecuencia_lluvia$RAIN, na.rm = T))/k),right = F, na.rm = T, include.lowest = TRUE)

#Se le adjuntan los intervalos a la tabla que tenemos de anomalia y de region
Frecuencia_lluvia<-Frecuencia_lluvia%>%mutate(IntervaloLluvia=intervalos)

#Se genera la tabla de frecuencias

FA<-table(Frecuencia_lluvia$IntervaloLluvia,Frecuencia_lluvia$station)

#Se coloca la matriz en un Data Frame
FA<-as.data.frame(FA)
FA<-FA%>%spread(Var2,Freq)

FA<-rbind(FA, c("Total",colSums(Filter(is.numeric, FA))))

#Se contruye la tabla que va ser pasada a latex
print(xtable(FA, type = "latex", tabular.environment="longtable"),include.rownames=FALSE, file = "frecuenciaLluvia.tex")

#Se elimina la tabla que tiene las frecuencias segun temperatura y anomalia
rm(FA,Frecuencia_lluvia,intervalos)



```

```{r}
#Frecuencia de PM2
Frecuencia_PM2.5<-data%>%select(PM2.5,station)

#Se calcula la cantidad de clases que deberían haber
k<-nclass.Sturges(Frecuencia_PM2.5$PM2.5)

#Se contruyen los intervalos
intervalos<-cut(Frecuencia_PM2.5$PM2.5,breaks = seq(min(Frecuencia_PM2.5$PM2.5, na.rm = T),max(Frecuencia_PM2.5$PM2.5, na.rm = T),(max(Frecuencia_PM2.5$PM2.5, na.rm = T)-min(Frecuencia_PM2.5$PM2.5, na.rm = T))/k),right = F, na.rm = T, include.lowest = TRUE)

#Se le adjuntan los intervalos a la tabla que tenemos de anomalia y de region
Frecuencia_PM2.5<-Frecuencia_PM2.5%>%mutate(IntervaloPM2=intervalos)

#Se genera la tabla de frecuencias

FA<-table(Frecuencia_PM2.5$IntervaloPM2,Frecuencia_PM2.5$station)
#FA<-prop.table(FA)
#Se coloca la matriz en un Data Frame
FA<-as.data.frame(FA)
FA<-FA%>%spread(Var2,Freq)
FA<-rbind(FA, c("Total",colSums(Filter(is.numeric, FA))))


#Se contruye la tabla que va ser pasada a latex
print(xtable(FA, type = "latex", tabular.environment="longtable"),include.rownames=FALSE, file = "frecuenciasPM2.tex")

#Se elimina la tabla que tiene las frecuencias segun temperatura y anomalia
rm(FA,Frecuencia_PM2.5,intervalos)



```





# Modelling

We are going to mode using Bayesian Analysis of State Space Models.
What we are going to do is the nextone:

1. Select the station.
2. Delete the last 31 observations.
3. We take the mean of each variable.
4. Apply the model, taking in consideration one new variable.
5. Test fit using AIC.
6. Select best model. 
7. Move to step 3 again to select another new variable, until finish with all variables.
8. Forecast the last 31 observations.
```{r}
data%<>%mutate("Date"=as.Date(paste(year,month,day,sep="-"),format="%Y-%m-%d"))
head(data)

data_means <- data%>%group_by(station,Date)%>%summarise("PM2.5"=mean(PM2.5,na.rm=TRUE),
                "SO2"=mean(SO2,na.rm=TRUE),
                "NO2"=mean(NO2,na.rm=TRUE),
                "CO"=mean(CO,na.rm=TRUE),
                "O3"=mean(O3,na.rm=TRUE),
                "TEMP"=mean(TEMP,na.rm=TRUE),
                "PRES"=mean(PRES,na.rm=TRUE),
                "DEWP"=mean(DEWP,na.rm=TRUE),
                "RAIN"=mean(RAIN,na.rm=TRUE),
                "WSPM"=mean(WSPM,na.rm=TRUE))
data_means[is.na(data_means)]<-NA
data_means%<>%mutate("Julian"=as.POSIXlt(Date)$yday)
write.csv(file="data_means.csv",data_means)
data_means%<>%mutate("I1"=0<=WSPM && WSPM <=2,"I2"= 2<WSPM && WSPM <=4,
                    "I3"= 4<WSPM && WSPM <=6, "I4"= 6<WSPM && WSPM <=8)

ggsave("cor_means.pdf",ggcorrplot(cor(data_means[,-c(1,2)],use = "complete.obs")))
#hist(data_means$PM2.5)



```


```{r}
#For the next
#We are going to use the function
#fit_dlm that is part of the package ecoforecast
AIC <- function(y,y_hat,k){
    SSE <- sum((y-y_hat)^2)
    n <- length(y)
    AIC <- log(SSE/n)+(n+2*(k+1))/n
    return(AIC)
}

#Example of structure function
#dlm <- fit_dlm(model=list(obs="PM2.5",fixed="~ 1 + X + Variable"))
#cat(dlm) returns the code created and given to rjags
dlm <- function(data,arg,k){
    print('hola')
    fit <- fit_dlm(model = list(obs="PM2.5", fixed = arg),data)
    smooth <- as.matrix(fit$predict)
    return(AIC(data$PM2.5,colMeans(smooth),k))

}

concat <- function(best_model,variable){
    return(paste(best_model,variable, sep = " + "))
}
fit <- function(station,data){
    data_train <- data%>%filter(station==station)
    data_train <- data_train[-(nrow(data_train)-(0:31)),]
    variables <- colnames(data_train[,-(1:2)])
    
    best_model <- "~ 1 + X"
    k <- 2
    while(length(variables)>=1){
        #print("Hola")
        best_aux <- unlist(lapply(FUN = concat, X=variables,best_model = best_model))
        fn <- function(X){
            head(data_train)
            return(dlm(data=data_train,arg=X,k=k))            
        }
        AIC_aux<-numeric()
        for(j in best_aux){
            AIC_aux[length(AIC_aux)+1] <- fn(X=j)
        }
        min <- min(AIC_aux)
        if (AIC<=min){
         break   
        }else{
            variable <- variables[which(AIC_aux==min)[1]]
            variables <- variables[-which(AIC_aux==min)[1]]
            best_model <- paste(best_model,variable,sep = " + ")
            k <- k+1
        }
    }
    return(data.frame("Station"=station,"Model" = best_model,"AIC" = AIC))
}
models <- data.frame("Station" = character(),"Model" = character(),"AIC"=numeric())
for(i in stations){
    model_aux <- fit(i,data_means)
   rbind(models,model_aux)
}
```


```{r}
#Give that we don't have enough time we are going to take one model for each station
#We are going to take CO and WSPM

for (j in stations){
    data_test <- data_means%>%filter(station == j )
    data_test[(nrow(data_test)-(0:31)),] <-NA #We assign NA
    assign(paste("Model",j,sep="_"),fit_dlm(model = list(obs="PM2.5", fixed = "~ 1 + X + CO + Julian + I1 + I2 + I3 + I4"),data_test)) 
}

#prueba <- fit_dlm(model=list(obs="logy",fixed="~ 1 + X + Julian"),data_test)
#estimation <- exp(as.matrix(prueba$predict))
#estimacion<-colMeans(estimation)

parameters <- data.frame("Station"=character(),"betaCO"=numeric(),"betaIntercept"=numeric(),"betaWSPM"=numeric(),"betaX"=numeric(),"tau_add"=numeric(),"tau_obs"=numeric())
for (j in stations){
    model <- get(paste("Model",j,sep="_"))   
    params <- as.matrix(model$params)
    means <-  colMeans(params)
    aux <- data.frame("Station"=j,"betaCO"=means[1],"betaIntercept"=means[2],"betaWSPM"=means[3],"betaX"=means[4],"tau_add"=means[5],"tau_obs"=means[6])
    rbind(parameters,aux)
}


#Used to write CSV with information
for (j in stations){
    model <- get(paste("Model",j,sep="_"))   
    params <- as.matrix(model$params)
    write.csv(file=paste(paste("params",j,sep="_"),"csv",sep="."),params)
}


for (j in stations){
    model <- get(paste("Model",j,sep="_"))   
    predict <- as.matrix(model$predict)
    write.csv(file=paste(paste("predict",j,sep="_"),"csv",sep="."),predict)
}

#colMeans(as.matrix(Model_Aotizhongxin$params))
```

```{r}
#We proceeed to add every estimation
data_means%<>%mutate("Predict"=0,"Q1"=0,"Q3"=0)

for (j in stations){
    model <- get(paste("Model",j,sep = "_"))
    predict <- as.matrix(model$predict)
    means <- colMeans(predict)
    quantile_1 <- apply(predict,2,quantile,c(0.025))
    quantile_3 <- apply(predict,2,quantile,c(0.975))
    station <- data_means$station==j
    data_means$Predict[station] <- means
    data_means$Q1[station] <- quantile_1
    data_means$Q3[station] <- quantile_3
}


```


```{r}
options(repr.plot.width=, repr.plot.height=8)
data_means%<>%mutate(Year=format(Date,"%Y"))
data_means%<>%mutate(Month_date=as.Date(format(Date,"%d-%m"),format="%d-%m"))


for(i in stations){
    ggsave(filename=paste("times_serie","_",i,".pdf",sep=""),data_means%>%filter(station== i)%>%ggplot(aes(x=Date,y=PM2.5))+geom_point(color="blue",alpha=0.4)+geom_line(aes(x=Date,y=Predict),color="red",alpha=0.4)+scale_x_date(date_labels = "%Y")+  geom_ribbon(aes(ymin = Q1, ymax = Q3), alpha = 0.4)+ylab("PM2.5")+xlab("Fecha")+theme_minimal()+theme(text=element_text(size=24)),width=20,height=10)
}

View(data_means)

```


```{r}
parameters <- data.frame("Station"=character(),"betaCO"=numeric(),"betaIntercept"=numeric(),"betaWSPM"=numeric(),"betaX"=numeric())
for (j in stations){
    model <- get(paste("Model",j,sep="_"))   
    p <-  colMeans(as.matrix(model$params))
    
    aux <- data.frame("Station"=j,"betaCO"=p[1],"beta_0-2"=p[2],"beta_2-4"=p[3],"beta_4-6"=p[4],"beta_6-8"=p[5],"betaIntercept"=p[6],"betaJulian"=p[7],"betaJulian"=p[8],"betaX"=p[9])
    parameters <- rbind(parameters,aux)
}


print(xtable(parameters, type = "latex", tabular.environment="longtable"),
    include.rownames=FALSE, file = "means_params.tex")
```

# Second and last chance modelling
```{r}
#We are going to use dlmModReg, and dlmMLE
library(dlm)
#For estimate by date
#df_contamination <- read.csv("data_means.csv")
#plot(diff(df_contamination_Aotizhongxin$PM2.5),type = "l")

#For estimate bu month
data%<>%mutate("Date"=as.Date(paste(year,month,day,sep="-"),format="%Y-%m-%d"))
data%<>%mutate("YM"=format(as.Date(Date,"%Y-%m-%d"),"%Y-%m"))
df_contamination <- data%>%group_by(station,YM)%>%summarise("PM2.5"=mean(PM2.5,na.rm=TRUE),
                "SO2"=mean(SO2,na.rm=TRUE),
                "NO2"=mean(NO2,na.rm=TRUE),
                "CO"=mean(CO,na.rm=TRUE),
                "O3"=mean(O3,na.rm=TRUE),
                "TEMP"=mean(TEMP,na.rm=TRUE),
                "PRES"=mean(PRES,na.rm=TRUE),
                "DEWP"=mean(DEWP,na.rm=TRUE),
                "RAIN"=mean(RAIN,na.rm=TRUE),
                "WSPM"=mean(WSPM,na.rm=TRUE))

#For both
df_contamination_Aotizhongxin <- df_contamination%>%filter(station == "Aotizhongxin")


build_model <- function (u){
        u <- exp(u)
        dlmModReg(data.frame(diff(log(as.numeric(df_contamination_Aotizhongxin$WSPM))),diff(log(df_contamination_Aotizhongxin$CO))), dV = u[1],dW = u[2:length(u)])
}



outMLE <- dlmMLE(diff(log(df_contamination_Aotizhongxin$PM2.5)),parm = rep(1,4),build_model)
df_contamination_estimated <- build_model(outMLE$par)
dlm_filtered <- dlmFilter(c(diff(log(df_contamination_Aotizhongxin$PM2.5)), rep(NA,4)),df_contamination_estimated)#Add NA to predict

plot(diff(log(df_contamination_Aotizhongxin$PM2.5)),type = "l")
n <- length(dlm_filtered$f)
lines(dlm_filtered$f,lty = "longdash")
dlmLL(diff(log(df_contamination_Aotizhongxin$PM2.5)),df_contamination_estimated)
#dlm_contaminacion_forecast <- dlmForecast(dlm_filtered,nAhead = 10,sampleNew = 10)
colnames(df_contamination_Aotizhongxin)
```

In this case what we have done is to estimate the rates of the variables

```{r}
#We are going to work with the month change 
build_model <- function (df_variables,u){
        u <- exp(u)
        dlmModReg(df_variables, dV = u[1],dW = u[2:length(u)])
}

dlm_aic <- function(loglik,coef){
    2*loglik+2*sum(coef)
}


#We create a function to select the best model using AIC criterion
#This function produce a data frame with the log diffs of the data
diff_variables <- function(df,station){
        df <- df%>%filter(station == station)
        
        df <-df%>%mutate("YM"=format(as.Date(Date,"%Y-%m-%d"),"%Y-%m"))
        
        df <- df%>%group_by(YM)%>%summarise("PM2.5"=mean(PM2.5,na.rm=TRUE),
                "SO2"=mean(SO2,na.rm=TRUE),
                "NO2"=mean(NO2,na.rm=TRUE),
                "CO"=mean(CO,na.rm=TRUE),
                "O3"=mean(O3,na.rm=TRUE),
                "TEMP"=mean(TEMP,na.rm=TRUE),
                "PRES"=mean(PRES,na.rm=TRUE),
                "DEWP"=mean(DEWP,na.rm=TRUE),
                "RAIN"=mean(RAIN,na.rm=TRUE),
                "WSPM"=mean(WSPM,na.rm=TRUE))
        name_cols <- colnames(df)
        columns <- ncol(df)
        #print(columns)
        for(i in 2:columns){
            df <- df%>%mutate(name = log(as.numeric(unlist(df[,i])))-log(as.numeric(unlist(lag(df[,i])))))
            colnames(df)[ncol(df)] <- paste("diff",name_cols[i],sep = "_")
            #print(head(df))
        }
        df[is.na(df)]<- NA
        df[] <- lapply(df, function(i) if(is.numeric(i)) ifelse(is.infinite(i), NA, i) else i)
        return(df)

        
}
best_dlm <- function(df,station){
    df <- diff_variables(df,station)
    name_columns <- colnames(df)
    name_columns <- grepl("diff_",name_columns)
    df <- df[,name_columns]
    name_columns <- colnames(df)
    df_for_forecast <- df[-seq(nrow(df)-5,nrow(df),by=1),]
    n_columns <- ncol(df_for_forecast)
    model_selected <-character()
    fn <- function(aux){
        aux <- c(aux,model_selected)
        #print(aux)
        df_auxiliar <- df_for_forecast%>%select(aux)
        aic <- tryCatch(return(dlm_aic(dlmLL(df_for_forecast$diff_PM2.5,dlmModReg(df_auxiliar)),length(aux)+1)),error = function(e){return(NA)})
        return(aic)
    }

    for(i in 1:n_columns){
        if(i == 1){
            aic_aux <- sapply(name_columns,FUN = fn)
            aic <- min(aic_aux,na.rm = TRUE)
            variable_selected <- which(aic_aux == aic)[1]
            model_selected <- name_columns[variable_selected]
            name_columns <- name_columns[-variable_selected]
            
        }else{
            aic_aux <- sapply(name_columns,FUN = fn)
            aic_aux[is.infinite(-aic_aux)] <- NA
            aic_aux[is.infinite(aic_aux)] <- NA
            #print(aic_aux)
            if(aic>min(aic_aux, na.rm =TRUE)){
                aic <- min(aic_aux, na.rm =TRUE)
                variable_selected <- which(aic_aux == aic)[1]
                model_selected <- c(model_selected,name_columns[variable_selected])
                name_columns <- name_columns[-variable_selected]
            }else{
                break
            }
        }
    }
    return(paste(model_selected,aic,collapse = "+",sep = " "))
}

df_adjustements <- data.frame("Station"=character(),"Model_MLE"=character())
for(i in 1:length(stations)){
    df_adjustements[i,1] <- stations[i]
    df_station <- data%>%filter(station == stations[i])
    df_adjustements[i,2] <- best_dlm(df_station,stations[i])
}


```

